# ResNet â€“ Residual Learning Framework

## Overview

This folder contains an implementation of ResNet, introducing residual connections to enable training of very deep networks.

---

## Architecture Highlights

- Residual Blocks
- Skip Connections
- Identity Mapping
- Batch Normalization

---

## Core Idea

Instead of learning H(x), the network learns:

F(x) + x

This helps mitigate vanishing gradient problems.

---

## Key Concepts Explored

- Residual learning
- Gradient flow in deep networks
- Training stability in 50+ layer models

---

## Observations

- Residual connections allow very deep architectures
- Improved convergence compared to plain deep networks
