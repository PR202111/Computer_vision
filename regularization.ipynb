{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"V5E1","authorship_tag":"ABX9TyMpuZ9Vm+C8/c21ix3KJ1mj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","execution_count":4,"metadata":{"id":"m6KQL4ZUlvPj","executionInfo":{"status":"ok","timestamp":1768470666384,"user_tz":-330,"elapsed":14611,"user":{"displayName":"Prashant Raj","userId":"13131792136088247515"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"566a727f-8019-4c89-d2f9-95774a7f5df0"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/jax/_src/cloud_tpu_init.py:86: UserWarning: Transparent hugepages are not enabled. TPU runtime startup and shutdown time should be significantly improved on TPU v5e and newer. If not already set, you may need to enable transparent hugepages in your VM image (sudo sh -c \"echo always > /sys/kernel/mm/transparent_hugepage/enabled\")\n","  warnings.warn(\n"]}],"source":["import tensorflow as tf\n","from tensorflow import keras\n","import matplotlib.pyplot as plt\n"]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","\n","# Image parameters\n","img_h = 16\n","img_w = 16\n","channels = 3\n","\n","# Class names\n","class_names = [\"daisy\", \"dandelion\", \"roses\", \"sunflowers\", \"tulips\"]\n","class_names_tf = tf.constant(class_names)  # ✅ FIX\n","\n","# ------------------------------------------------------\n","# Image loading\n","# ------------------------------------------------------\n","def read_decode(file_name, resize_dim):\n","    img_bytes = tf.io.read_file(file_name)\n","    img = tf.image.decode_jpeg(img_bytes, channels=channels)  # ✅ force RGB\n","    img = tf.image.convert_image_dtype(img, tf.float32)\n","    img = tf.image.resize(img, resize_dim)\n","    return img\n","\n","# ------------------------------------------------------\n","# CSV parsing\n","# ------------------------------------------------------\n","def parse_csvline(csv_line):\n","    record_default = [\"\", \"\"]\n","    file_name, label_string = tf.io.decode_csv(csv_line, record_default)\n","\n","    img = read_decode(file_name, [img_h, img_w])\n","\n","    # ✅ FIXED LABEL ENCODING\n","    label = tf.argmax(\n","        tf.cast(tf.equal(class_names_tf, label_string), tf.int32)\n","    )\n","\n","    return img, label\n","\n","# ------------------------------------------------------\n","# Datasets\n","# ------------------------------------------------------\n","train_dataset = (\n","    tf.data.TextLineDataset(\"gs://cloud-ml-data/img/flower_photos/train_set.csv\")\n","    .map(parse_csvline, num_parallel_calls=tf.data.AUTOTUNE)\n","    .batch(8)\n","    .prefetch(tf.data.AUTOTUNE)\n",")\n","\n","eval_dataset = (\n","    tf.data.TextLineDataset(\"gs://cloud-ml-data/img/flower_photos/eval_set.csv\")\n","    .map(parse_csvline, num_parallel_calls=tf.data.AUTOTUNE)\n","    .batch(8)\n","    .prefetch(tf.data.AUTOTUNE)\n",")\n","\n","# ------------------------------------------------------\n","# Model\n","# ------------------------------------------------------\n","model = keras.Sequential([\n","    keras.layers.Flatten(input_shape=(img_h, img_w, channels)),\n","    keras.layers.Dense(\n","        128,\n","        kernel_regularizer=keras.regularizers.l2(0.01),\n","        use_bias=False\n","    ),\n","    keras.layers.BatchNormalization(),\n","    keras.layers.Activation(\"relu\"),\n","    keras.layers.Dropout(0.5),\n","    keras.layers.Dense(len(class_names), activation=\"softmax\")\n","])\n","\n","# ------------------------------------------------------\n","# Compile\n","# ------------------------------------------------------\n","model.compile(\n","    optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n","    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n","    metrics=[\"accuracy\"]\n",")\n","\n","# ------------------------------------------------------\n","# Train\n","# ------------------------------------------------------\n","model.fit(\n","    train_dataset,\n","    validation_data=eval_dataset,\n","    epochs=10,\n","    callbacks=[\n","        tf.keras.callbacks.EarlyStopping(\n","            monitor='val_loss',\n","            patience=3,\n","            restore_best_weights=True\n","        )\n","    ]\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X1zoj3yJnuMO","executionInfo":{"status":"ok","timestamp":1768470796531,"user_tz":-330,"elapsed":130134,"user":{"displayName":"Prashant Raj","userId":"13131792136088247515"}},"outputId":"f81e6b33-b53c-4fcb-d1f3-d5f692834ffa"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["    412/Unknown \u001b[1m15s\u001b[0m 33ms/step - accuracy: 0.2551 - loss: 4.2179"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/trainers/epoch_iterator.py:160: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self._interrupted_warning()\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 38ms/step - accuracy: 0.2552 - loss: 4.2170 - val_accuracy: 0.3973 - val_loss: 3.4860\n","Epoch 2/10\n","\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 28ms/step - accuracy: 0.3556 - loss: 3.6567 - val_accuracy: 0.4324 - val_loss: 3.2259\n","Epoch 3/10\n","\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 29ms/step - accuracy: 0.3991 - loss: 3.3870 - val_accuracy: 0.4730 - val_loss: 3.0895\n","Epoch 4/10\n","\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 30ms/step - accuracy: 0.4340 - loss: 3.1839 - val_accuracy: 0.4892 - val_loss: 2.9596\n","Epoch 5/10\n","\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 30ms/step - accuracy: 0.4666 - loss: 3.0004 - val_accuracy: 0.4459 - val_loss: 2.9077\n","Epoch 6/10\n","\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 31ms/step - accuracy: 0.4850 - loss: 2.8428 - val_accuracy: 0.4459 - val_loss: 2.7758\n","Epoch 7/10\n","\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 30ms/step - accuracy: 0.4908 - loss: 2.7135 - val_accuracy: 0.5000 - val_loss: 2.6373\n","Epoch 8/10\n","\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 32ms/step - accuracy: 0.5146 - loss: 2.5655 - val_accuracy: 0.4649 - val_loss: 2.5641\n","Epoch 9/10\n","\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 31ms/step - accuracy: 0.5193 - loss: 2.4805 - val_accuracy: 0.4973 - val_loss: 2.4679\n","Epoch 10/10\n","\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 31ms/step - accuracy: 0.5297 - loss: 2.3484 - val_accuracy: 0.4757 - val_loss: 2.3869\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x797cb3410050>"]},"metadata":{},"execution_count":5}]}]}