# Vision Transformer (ViT)

## Overview

Implementation of the Vision Transformer architecture, replacing convolutional inductive bias with self-attention mechanisms.

---

## Architecture Components

- Patch Embedding Layer
- Positional Encoding
- Multi-Head Self Attention
- Feed Forward Network
- Layer Normalization
- Classification (CLS) Token

---

## Key Concepts Explored

- Image-to-patch tokenization
- Global attention across spatial positions
- Comparison with CNN locality bias

---

## Observations

- Captures long-range dependencies
- Requires larger datasets compared to CNNs
- Computationally intensive
